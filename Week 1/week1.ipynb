{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "path = 'C:/Users/OptimusPrime/Desktop/Studia/NLP1/Natural-Language-Processing-1/Week 1/Datasets'\n",
    "languages = ['english', 'spanish', 'polish', 'finnish', 'german', 'italian']\n",
    "languages_encoder = {'english': 0, 'spanish': 1, 'polish': 2, 'finnish': 3, 'german': 4, 'italian': 5}\n",
    "languages_decoder = {0: 'english', 1: 'spanish', 2: 'polish', 3: 'finnish', 4: 'german', 5: 'italian'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_label_data_from(path):\n",
    "    X = list()\n",
    "    y = list()\n",
    "    for dataset in os.listdir(path):\n",
    "        if dataset.endswith('.txt'):\n",
    "            with open(path + '\\\\' + dataset, 'r', errors='ignore') as f:\n",
    "                text = f.read() \n",
    "                text = re.sub(r\"[\\\\\\^\\$\\.\\|\\?\\*\\+\\(\\)\\[\\]\\{1-9\\\"!\\-_=%<>]\", '', text)\n",
    "                lines = text.split('\\n')\n",
    "                lines = [_ for _ in lines if _ != '']\n",
    "                X += lines\n",
    "            for language in languages:\n",
    "                if language in dataset:\n",
    "                    y += len(lines)*[languages_encoder[language]]\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = load_preprocess_label_data_from(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of train samples:140340\n",
      "Total number of test samples:35086\n",
      "Number of train lines for each language:\n",
      "{'english': 26493, 'spanish': 24896, 'polish': 679, 'finnish': 24961, 'german': 53864, 'italian': 9447}\n",
      "Number of test lines for each language:\n",
      "{'english': 6608, 'spanish': 6231, 'polish': 153, 'finnish': 6171, 'german': 13566, 'italian': 2357}\n"
     ]
    }
   ],
   "source": [
    "def count_train_and_test_samples():\n",
    "    print(\"Total number of train samples:\" + str(len(y_train)))\n",
    "    print(\"Total number of test samples:\" + str(len(y_test))) \n",
    "\n",
    "    train_samples_counter = dict()\n",
    "    test_samples_counter = dict()\n",
    "\n",
    "    for _ in languages:\n",
    "        train_samples_counter[_] = 0\n",
    "        test_samples_counter[_] = 0\n",
    "\n",
    "    for language_id in y_train:\n",
    "        train_samples_counter[languages_decoder[language_id]] += 1\n",
    "    print(\"Number of train lines for each language:\")\n",
    "    print(train_samples_counter)    \n",
    "        \n",
    "    for language_id in y_test:\n",
    "        test_samples_counter[languages_decoder[language_id]] += 1\n",
    "    print(\"Number of test lines for each language:\")\n",
    "    print(test_samples_counter)    \n",
    "    \n",
    "count_train_and_test_samples()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-gram results:\n",
      "\n",
      "Validation sample: Cześć, mam dwadzieścia trzy lata, jak się masz?\n",
      "Predictions:\n",
      "english: 0.22%\t\n",
      "spanish: 3.68%\t\n",
      "polish: 91.29%\t\n",
      "finnish: 2.49%\t\n",
      "german: 0.65%\t\n",
      "italian: 1.67%\t\n",
      "\n",
      "Validation sample: Hi, I'm twenty-three, how are you?\n",
      "Predictions:\n",
      "english: 98.94%\t\n",
      "spanish: 0.28%\t\n",
      "polish: 0.55%\t\n",
      "finnish: 0.09%\t\n",
      "german: 0.05%\t\n",
      "italian: 0.09%\t\n",
      "\n",
      "Validation sample: Hola tengo veintitrés, ¿cómo estás?\n",
      "Predictions:\n",
      "english: 8.13%\t\n",
      "spanish: 88.02%\t\n",
      "polish: 0.39%\t\n",
      "finnish: 0.80%\t\n",
      "german: 0.57%\t\n",
      "italian: 2.09%\t\n",
      "\n",
      "Validation sample: Ciao, sono ventitré, come stai?\n",
      "Predictions:\n",
      "english: 3.06%\t\n",
      "spanish: 16.23%\t\n",
      "polish: 0.12%\t\n",
      "finnish: 0.19%\t\n",
      "german: 0.45%\t\n",
      "italian: 79.95%\t\n",
      "\n",
      "Validation sample: Hallo, ich bin dreiundzwanzig, wie geht es dir?\n",
      "Predictions:\n",
      "english: 0.15%\t\n",
      "spanish: 0.05%\t\n",
      "polish: 0.19%\t\n",
      "finnish: 0.01%\t\n",
      "german: 99.20%\t\n",
      "italian: 0.40%\t\n",
      "\n",
      "Validation sample: Hei Im kaksikymmentäkolme, miten olet?\n",
      "Predictions:\n",
      "english: 0.44%\t\n",
      "spanish: 0.01%\t\n",
      "polish: 0.44%\t\n",
      "finnish: 79.71%\t\n",
      "german: 19.14%\t\n",
      "italian: 0.27%\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_proba(probabilities):\n",
    "    print('Predictions:')\n",
    "    for lang, prob in zip(label_names, probabilities[0]):\n",
    "        print(lang + ': ' + str('%.2f' % float(100 * prob)) + '%\\t')\n",
    "        \n",
    "validation_samples = [[\"Cześć, mam dwadzieścia trzy lata, jak się masz?\"], \n",
    "              [\"Hi, I'm twenty-three, how are you?\"], \n",
    "              [\"Hola tengo veintitrés, ¿cómo estás?\"],\n",
    "              [\"Ciao, sono ventitré, come stai?\"],\n",
    "              [\"Hallo, ich bin dreiundzwanzig, wie geht es dir?\"],\n",
    "              [\"Hei Im kaksikymmentäkolme, miten olet?\"]]\n",
    "ngram_ranges = [2, 3, 4, 5, 6]\n",
    "\n",
    "polish_scores = list()\n",
    "english_scores = list()\n",
    "spanish_scores = list()\n",
    "italian_scores = list()\n",
    "german_scores = list()\n",
    "finnish_scores = list()\n",
    "\n",
    "for n in ngram_ranges:\n",
    "    pipe = Pipeline([('vectorizer', TfidfVectorizer(ngram_range=(n, n), analyzer='char')), ('clf', LogisticRegression())])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    print(str(n) + '-gram results:')\n",
    "    polish_scores.append(pipe.predict_proba([\"Cześć, mam dwadzieścia trzy lata, jak się masz?\"])[0][2])\n",
    "    english_scores.append(pipe.predict_proba([\"Hi, I'm twenty-three, how are you?\"])[0][0])\n",
    "    spanish_scores.append(pipe.predict_proba([\"Hola tengo veintitrés, ¿cómo estás?\"])[0][1])\n",
    "    italian_scores.append(pipe.predict_proba([\"Ciao, sono ventitré, come stai?\"])[0][5])\n",
    "    german_scores.append(pipe.predict_proba([\"Hallo, ich bin dreiundzwanzig, wie geht es dir?\"])[0][4])\n",
    "    finnish_scores.append(pipe.predict_proba([\"Hei Im kaksikymmentäkolme, miten olet?\"])[0][3])\n",
    "\n",
    "    print(\"\\nValidation sample: Cześć, mam dwadzieścia trzy lata, jak się masz?\")\n",
    "    show_proba(pipe.predict_proba([\"Cześć, mam dwadzieścia trzy lata, jak się masz?\"]))\n",
    "    print(\"\\nValidation sample: Hi, I'm twenty-three, how are you?\")\n",
    "    show_proba(pipe.predict_proba([\"Hi, I'm twenty-three, how are you?\"]))\n",
    "    print(\"\\nValidation sample: Hola tengo veintitrés, ¿cómo estás?\")\n",
    "    show_proba(pipe.predict_proba([\"Hola tengo veintitrés, ¿cómo estás?\"]))\n",
    "    print(\"\\nValidation sample: Ciao, sono ventitré, come stai?\")\n",
    "    show_proba(pipe.predict_proba([\"Ciao, sono ventitré, come stai?\"]))\n",
    "    print(\"\\nValidation sample: Hallo, ich bin dreiundzwanzig, wie geht es dir?\")\n",
    "    show_proba(pipe.predict_proba([\"Hallo, ich bin dreiundzwanzig, wie geht es dir?\"]))\n",
    "    print(\"\\nValidation sample: Hei Im kaksikymmentäkolme, miten olet?\")\n",
    "    show_proba(pipe.predict_proba([\"Hei Im kaksikymmentäkolme, miten olet?\"]))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nns = ['2', '3', '4', '5', '6']\n",
    "\n",
    "plt.figure(figsize=(20, 3))\n",
    "\n",
    "plt.subplot(161)\n",
    "plt.title('Polish')\n",
    "plt.bar(nns, polish_scores)\n",
    "plt.xlabel('\\'n\\'')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.subplot(162)\n",
    "plt.title('English')\n",
    "plt.bar(nns, english_scores)\n",
    "plt.xlabel('\\'n\\'')\n",
    "plt.subplot(163)\n",
    "plt.title('Spanish')\n",
    "plt.bar(nns, spanish_scores)\n",
    "plt.xlabel('\\'n\\'')\n",
    "plt.subplot(164)\n",
    "plt.title('Italian')\n",
    "plt.bar(nns, italian_scores)\n",
    "plt.xlabel('\\'n\\'')\n",
    "plt.subplot(165)\n",
    "plt.title('German')\n",
    "plt.bar(nns, german_scores)\n",
    "plt.xlabel('\\'n\\'')\n",
    "plt.subplot(166)\n",
    "plt.title('Finnish')\n",
    "plt.bar(nns, finnish_scores)\n",
    "plt.xlabel('\\'n\\'')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
