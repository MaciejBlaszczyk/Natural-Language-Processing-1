{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import numpy as np\n",
    "import codecs\n",
    "import re\n",
    "import operator\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
    "from sklearn.cluster import DBSCAN\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = 'C:/Users/OptimusPrime/Desktop/Studia/NLP1/Natural-Language-Processing-1/Week 3/Data'\n",
    "def load_text():\n",
    "    with codecs.open(datasets_path + '\\\\lines.txt', 'r', 'utf-8') as f:\n",
    "        raw_text = f.read().lower()\n",
    "        raw_lines = raw_text.split('\\n')\n",
    "        text = re.sub(r\"[\\\\\\^\\$\\.\\|\\?\\*\\+\\(\\)\\[\\]\\{0-9\\\"!\\-_=%<>,'/;:@]\", ' ', raw_text) #preprocessing\n",
    "        text = re.sub(' +', ' ', text)\n",
    "        text_lines = text.split('\\n')\n",
    "        return np.array(text_lines)\n",
    "text_lines = load_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,1), analyzer='word')\n",
    "freq_matrix = cv.fit_transform(text_lines)\n",
    "words = cv.get_feature_names()\n",
    "occurence_number = freq_matrix.sum(axis=0).A1\n",
    "\n",
    "occurence_number, words = (list(t) for t in zip(*sorted(zip(occurence_number, words), reverse=True)))\n",
    "\n",
    "stop_list = [t[1] for t in zip(occurence_number, words) if t[0] > 110]\n",
    "\n",
    "filtered_lines = list()\n",
    "for line in text_lines: \n",
    "    line_words = line.split()\n",
    "    preprocessed_words = [word for word in line_words if word not in stop_list]\n",
    "    filtered_lines.append(' '.join(preprocessed_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop list:\n",
      "['ltd', 'tel', 'fax', 'china', 'co', 'road', 'no', 'ul', 'poland', 'logistics', 'sp', 'russia', 'of', 'petersburg', 'moscow', 'st', 'str', 'gdynia', 'building', 'shanghai', 'limited', 'pl', 'office', 'finland', 'rd', 'international', 'ningbo', 'llc', 'oy', 'and', 'ooo', 'city', 'shenzhen', 'street', 'room', 'district', 'as', 'floor', 'th', 'branch', 'forwarding', 'order', 'saint', 'industrial', 'warszawa', 'zhejiang', 'global', 'to', 'rm', 'hong', 'eori', 'kong', 'bldg', 'tower', 'lit', 'agent', 'company', 'polska', 'phone', 'fi', 'shipping', 'air', 'east', 'trade', 'taiwan', 'schenker', 'import', 'xiamen', 'trading', 'plaza', 'on', 'zone', 'attn', 'sea', 'line', 'the', 'box', 'town', 'cargo', 'behalf', 'south', 'inn', 'group', 'qingdao', 'business', 'damco', 'centre', 'park', 'kuehne', 'guangzhou', 'zip', 'vantaa', 'nagel', 'jiangsu', 'code', 'thailand', 'helsinki', 'freight', 'center', 'russian', 'panalpina', 'kotka', 'federation', 'province', 'for', 'com', 'mail', 'export', 'west', 'industry', 'world', 'korea', 'ocean']\n"
     ]
    }
   ],
   "source": [
    "print(\"Stop list:\")\n",
    "print(stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_matrix = freq_matrix.toarray()\n",
    "# to calculate distances cosine and dice metrics are used\n",
    "cosine_similarity_matrix = cosine_similarity(frequency_matrix)\n",
    "dice_similarity_matrix = pairwise_distances(frequency_matrix, metric='dice', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(algorithm='auto', eps=0.3, leaf_size=30, metric='precomputed',\n",
       "    metric_params=None, min_samples=0, n_jobs=-1, p=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_similarity_matrix[-1][-1] = 1.0 #no idea why but very last cell in matrix is NAN and must be exchanged with 1.0\n",
    "\n",
    "companies_codes = range(len(dice_similarity_matrix))\n",
    "\n",
    "# DBSCANN as a clustering algorithm, because it doesn't require number of clusters\n",
    "dbscn_dice = DBSCAN(eps=0.3, min_samples=0, metric='precomputed', n_jobs=-1)\n",
    "dbscn_cosine = DBSCAN(eps=0.3, min_samples=0, metric='precomputed', n_jobs=-1)\n",
    "\n",
    "dbscn_dice.fit(dice_similarity_matrix)\n",
    "dbscn_cosine.fit(1.0-cosine_similarity_matrix) #1.0-values because cosine metric gives 1.0 for the identical samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth labels aren't known, so the silhouette and davies-bouldin metrics are computed (they don't need true labels) \n",
    "silhouette_dice = metrics.silhouette_score(dice_similarity_matrix, dbscn_dice.labels_, metric='precomputed')\n",
    "silhouette_cosine = metrics.silhouette_score(cosine_similarity_matrix, dbscn_cosine.labels_, metric='precomputed')\n",
    "davies_bouldin_dice = metrics.davies_bouldin_score(frequency_matrix, dbscn_dice.labels_)\n",
    "davies_bouldin_cosine = metrics.davies_bouldin_score(frequency_matrix, dbscn_cosine.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for dice metric:\n",
      "0.32703129906893974\n",
      "Silhouette score for cosine metric:\n",
      "-0.6091528436018957\n",
      "Davies-Bouldin score for dice metric:\n",
      "0.7294880941984994\n",
      "Davies-Bouldin score for cosine metric:\n",
      "0.7718271731193386\n"
     ]
    }
   ],
   "source": [
    "print(\"Silhouette score for dice metric:\")\n",
    "print(silhouette_dice)\n",
    "print(\"Silhouette score for cosine metric:\")\n",
    "print(silhouette_cosine)\n",
    "print(\"Davies-Bouldin score for dice metric:\")\n",
    "print(davies_bouldin_dice)\n",
    "print(\"Davies-Bouldin score for cosine metric:\")\n",
    "print(davies_bouldin_cosine)\n",
    "#Both metrics indicate that dice metric to calculate distances performs better\n",
    "#(higher Silhouette score and lower Davies-Bouldin score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
